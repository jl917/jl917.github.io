"use strict";(self.webpackChunkrspress_doc_template=self.webpackChunkrspress_doc_template||[]).push([["244"],{6037:function(n,e,i){i.r(e),i.d(e,{default:()=>h});var r=i(5893),l=i(65);function s(n){let e={a:"a",h1:"h1",h3:"h3",h5:"h5",li:"li",ol:"ol",p:"p",ul:"ul",...(0,l.a)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(e.h1,{id:"fine-tuning-微调",children:[(0,r.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#fine-tuning-微调",children:"#"}),"Fine-tuning 微调"]}),"\n",(0,r.jsxs)(e.h3,{id:"소개",children:[(0,r.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#소개",children:"#"}),"소개"]}),"\n",(0,r.jsx)(e.p,{children:'파인튜닝은 특정 작업이나 도메인에 높은 적합성을 확보하기 위해, 이미 훈련된 대규모 언어 모델에 특정 데이터셋을 사용하여 추가적인 학습을 수행하는 작업을 말합니다.\n미세 조정은 표면적으로 모델 학습에 사용되는 기술이지만 일반적으로 "학습"이라고 하는 것과는 다른 프로세스입니다. 명확성을 위해 데이터 과학자는 일반적으로 후자를 이러한 맥락에서 사전 학습이라고 부릅니다.'}),"\n",(0,r.jsxs)(e.h3,{id:"방법",children:[(0,r.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#방법",children:"#"}),"방법"]}),"\n",(0,r.jsxs)(e.h5,{id:"full-fine-tuning",children:[(0,r.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#full-fine-tuning",children:"#"}),"Full Fine-tuning"]}),"\n",(0,r.jsx)(e.p,{children:"전체 파인튜닝은 모델의 모든 매개변수를 업데이트하여 모델 전체를 새로운 데이터에 맞춰 재학습하는 방식입니다.\n일반적으로 작업과 기존 학습된 모델의 차이가 크거나 모델의 높은 적응성이 필요할 때 사용합니다.\n많은 컴퓨팅 자원과 시간이 필요하지만 그만큼 성능 향상이 큽니다."}),"\n",(0,r.jsxs)(e.h5,{id:"partial-fine-tuning--layer-freezing",children:[(0,r.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#partial-fine-tuning--layer-freezing",children:"#"}),"Partial Fine-Tuning / Layer Freezing"]}),"\n",(0,r.jsx)(e.p,{children:"모델 전체를 다 학습시키지 않고, 특정 레이어만 학습시키는 방식입니다. 미세 조정 중 특정 레이어는 업데이트하지 못하도록 “얼려” 두는 기술입니다."}),"\n",(0,r.jsx)(e.p,{children:"Layer Freezing는 “여기 레이어는 학습하지 마라”라고 고정시키는 기술\nPartial Fine-Tuning “일부 레이어만 학습시키겠다”라는 전략"}),"\n",(0,r.jsxs)(e.h5,{id:"parameter-efficient-fine-tuningpeft",children:[(0,r.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#parameter-efficient-fine-tuningpeft",children:"#"}),"Parameter-Efficient Fine-Tuning(PEFT)"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Prompt Tuning: 입력 또는 학습 데이터에 맞춤형 프롬프트를 주입하여 프리픽스 튜닝을 간소화하고 모델을 학습시킵니다. 하드 프롬프트는 수동으로 생성되는 것이고, 소프트 프롬프트는 기본 모델에서 지식을 추출하여 AI가 생성한 숫자 문자열입니다."}),"\n",(0,r.jsx)(e.li,{children:"P-Tuning: 수동으로 생성한 프롬프트를 사용하는 대신 자동화된 프롬프트 훈련 및 생성을 도입하여 시간이 지남에 따라 더욱 영향력 있는 훈련 프롬프트를 생성합니다."}),"\n",(0,r.jsx)(e.li,{children:"Prefix-Tuning: 모든 매개변수를 고정된 상태로 유지하면서 접두사라고 하는 작업 특이적 연속 벡터를 각 트랜스포머 계층에 추가합니다. 이렇게 하면 접두사 조정 모델은 완전히 미세 조정된 비슷한 성능의 모델보다 매개변수를 천 배 이상 적게 저장합니다."}),"\n",(0,r.jsx)(e.li,{children:"LoRA: 트윈 저순위 분해 행렬을 사용하여 모델 가중치를 최소화하고 훈련 가능한 매개변수의 하위 집합을 더 줄입니다."}),"\n",(0,r.jsx)(e.li,{children:"QLoRA: 사전 학습된 각 매개변수의 가중치를 일반적인 32비트 가중치에서 단 4비트로 정량화 또는 표준화하는 LoRA의 확장 버전입니다. 따라서 QLoRA는 메모리를 상당히 절약하며, 단 하나의 GPU에서 LLM을 실행할 수 있습니다."}),"\n",(0,r.jsx)(e.li,{children:"Adapter Tuning: 모델의 각 트랜스포머 계층에 훈련 가능한 작업별 매개변수 몇 개를 삽입하는 작은 추가 기능입니다."}),"\n"]}),"\n",(0,r.jsxs)(e.h5,{id:"supervised-fine-tuning-sft",children:[(0,r.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#supervised-fine-tuning-sft",children:"#"}),"Supervised Fine-Tuning, SFT"]}),"\n",(0,r.jsx)(e.p,{children:"??"}),"\n",(0,r.jsxs)(e.h5,{id:"unsupervised-fine-tuning-uft",children:[(0,r.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#unsupervised-fine-tuning-uft",children:"#"}),"Unsupervised Fine-Tuning, UFT"]}),"\n",(0,r.jsx)(e.p,{children:"??"}),"\n",(0,r.jsxs)(e.h3,{id:"장점",children:[(0,r.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#장점",children:"#"}),"장점"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"일반 프롬프트보다 더 좋은 효과를 얻을수 있다."}),"\n",(0,r.jsx)(e.li,{children:"토큰사용도 줄일수 있다."}),"\n",(0,r.jsx)(e.li,{children:"속도가 빠르다"}),"\n"]}),"\n",(0,r.jsxs)(e.h3,{id:"단점",children:[(0,r.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#단점",children:"#"}),"단점"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"인력비용"}),"\n",(0,r.jsx)(e.li,{children:"복잡한 기술 역량"}),"\n",(0,r.jsx)(e.li,{children:"난이도가 높다"}),"\n"]}),"\n",(0,r.jsxs)(e.h3,{id:"튜닝",children:[(0,r.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#튜닝",children:"#"}),"튜닝"]}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"데이터셋 준비: 목표 작업에 필요한 입력(프롬프트)과 원하는 출력값을 매핑하는 레이블이 지정된 데이터셋을 확보하거나 생성해야 합니다. 요약과 같은 텍스트 생성 작업의 경우, 입력 텍스트와 요약된 출력값 쌍이 필요합니다."}),"\n",(0,r.jsx)(e.li,{children:"데이터셋 분할: 모범 사례에 따라 레이블이 지정된 데이터셋을 학습, 검증 및 테스트 세트로 분할합니다. 이렇게 하면 모델 학습, 하이퍼파라미터 튜닝 및 최종 평가를 위한 데이터가 분리됩니다."}),"\n",(0,r.jsx)(e.li,{children:"하이퍼파라미터 튜닝: 학습률, 배치 크기, 학습 스케줄과 같은 매개변수를 데이터에 가장 효과적인 방식으로 조정해야 합니다. 일반적으로 이 과정에는 소규모 검증 세트가 사용됩니다."}),"\n",(0,r.jsx)(e.li,{children:"모델 학습: 튜닝된 하이퍼파라미터를 사용하여 전체 학습 세트에서 모델 성능이 검증 세트에서 더 이상 향상되지 않을 때까지(조기 종료) 미세 조정 최적화 프로세스를 실행합니다."}),"\n",(0,r.jsx)(e.li,{children:"평가: 미세 조정된 모델의 성능을 실제 사용 사례에 대한 실제 예제로 구성된 별도의 테스트 세트에서 평가하여 실제 효율성을 추정합니다."}),"\n",(0,r.jsx)(e.li,{children:"배포 및 모니터링: 만족스러운 결과가 나오면, 미세 조정된 모델을 새로운 입력값에 대한 추론에 배포할 수 있습니다. 개념의 변화(concept drift)를 파악하기 위해 시간이 지남에 따라 모델의 성능과 정확도를 모니터링하는 것이 중요합니다."}),"\n"]}),"\n",(0,r.jsxs)(e.h3,{id:"데이터셋-거버넌스-구축",children:[(0,r.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#데이터셋-거버넌스-구축",children:"#"}),"데이터셋 거버넌스 구축"]}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"요구사항 분석시 데이터에 대해서도 체크"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"데이터의 종류"}),"\n",(0,r.jsx)(e.li,{children:"데이터의 수량"}),"\n",(0,r.jsx)(e.li,{children:"정답의 내용과 형식"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"기술팀과 기획팀의 협업"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"기획: 구체적인 요구사항과 사용자 시나리오를 제공"}),"\n",(0,r.jsx)(e.li,{children:"기술: 실현 가능성을 검토하고 필요한 데이터의 특성을 분석"}),"\n",(0,r.jsx)(e.li,{children:"데이터셋 구축 가이드라인을 작성."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"데이터셋 정의"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"입력 데이터의 형식과 특성"}),"\n",(0,r.jsx)(e.li,{children:"출력 데이터의 형식과 요구사항"}),"\n",(0,r.jsx)(e.li,{children:"중간 처리 과정에서 필요한 데이터 형식"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsx)(e.p,{children:"데이터 수집과 애플리케이션 설계/구현을 반복하면서 시스템을 개선"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.h3,{id:"데이터-증강-craft-방법론",children:[(0,r.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#데이터-증강-craft-방법론",children:"#"}),"데이터 증강 CRAFT 방법론"]}),"\n",(0,r.jsx)(e.p,{children:"CRAFT(Corpus Retrival and Augmentation for Fine-Tuning)는 소량의 데이만으로 특화된 대규모 데이터셋을 합성하고 증강하는 기술입니다.(LLM을 활용하여 데이터셋을 생성하는 방법론)\n핵심은 소수의 예시를 기반으로 대규모 데이터셋을 생성하는 것입니다. CRAFT는 다음과 같은 단계를 포함합니다:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"태스크의 기준을 명확히 정의"}),"\n",(0,r.jsx)(e.li,{children:"임베딩 데이터 베이스 구축"}),"\n",(0,r.jsx)(e.li,{children:"관련 문서 검색"}),"\n",(0,r.jsx)(e.li,{children:"LLM이 사용할 수 있는 형식으로 구조화"}),"\n",(0,r.jsx)(e.li,{children:"합성 샘플 생성"}),"\n"]}),"\n",(0,r.jsxs)(e.h3,{id:"기타-용어",children:[(0,r.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#기타-용어",children:"#"}),"기타 용어"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Fuzzy Matching: 유사한 샘플을 억제하는 기술"}),"\n",(0,r.jsx)(e.li,{children:"Data Deduplication: 중복된 샘플을 제거하는 기술"}),"\n",(0,r.jsx)(e.li,{children:"Data Filtering: 품질이 낮은 샘플을 제거하는 기술"}),"\n"]}),"\n",(0,r.jsxs)(e.h3,{id:"풀파인튜닝-vs-lora-vs-qlora",children:[(0,r.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#풀파인튜닝-vs-lora-vs-qlora",children:"#"}),"풀파인튜닝 vs LoRA vs QLoRA"]}),"\n",(0,r.jsxs)(e.h5,{id:"풀-파인튜닝",children:[(0,r.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#풀-파인튜닝",children:"#"}),"풀 파인튜닝"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"훈련 파라미터수: 100%, 모델의 전체 파라 미터를 학습시킨다"}),"\n",(0,r.jsx)(e.li,{children:"추가 모델 저장 공간: 크다(모델 크기의 4~6배가 더 필요하다)"}),"\n",(0,r.jsx)(e.li,{children:"메모리 요구사항: 매우 크다(예: 70B 모델 기준 최대 1TB)"}),"\n",(0,r.jsx)(e.li,{children:"추론 속도 영향: 없다"}),"\n",(0,r.jsxs)(e.li,{children:["장점\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"모든 파라미터가 조정 가능하므로 높은 유연 성을 가지고 있다"}),"\n",(0,r.jsx)(e.li,{children:"최고 성능 잠재력이 가장 크다"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["단점\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"자원을 많이 요구한 다(일반 개발자는 접 근이 어려움)."}),"\n",(0,r.jsx)(e.li,{children:"과적합 위험이 있고 학습속도가 느리다."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.h5,{id:"lora",children:[(0,r.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#lora",children:"#"}),"LoRA"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"훈련 파라미터수: 1% 미만만 학습시킨다(랭크 (rank) 값에 비례)"}),"\n",(0,r.jsx)(e.li,{children:"추가 모델 저장 공간: 매우 작다(수 MB 내외의 LORA 가중치만 저장)"}),"\n",(0,r.jsx)(e.li,{children:"메모리 요구사항: 중간 정도의 크기다(원본 모 델 + LORA 모듈)"}),"\n",(0,r.jsx)(e.li,{children:"추론 속도 영향: 없다"}),"\n",(0,r.jsxs)(e.li,{children:["장점\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"매우 가벼운 학습(자원 절약)이다."}),"\n",(0,r.jsx)(e.li,{children:"풀 파인튜닝에 준하는 성 능을 유지한다."}),"\n",(0,r.jsx)(e.li,{children:"파라미터 수가 작으므로 추론 시 부담 적다."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["단점\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"베이스 모델을 필요로 한 다(배포 시 LORA 모듈과 병합하거나 병렬 사용)."}),"\n",(0,r.jsx)(e.li,{children:"랭크(r) 등 하이퍼파라미 터 조정이 필요하다."}),"\n",(0,r.jsx)(e.li,{children:"랭크가 너무 낮으면 성능 이 저하된다."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.h5,{id:"qlora",children:[(0,r.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#qlora",children:"#"}),"QLoRA"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"훈련 파라미터수: 1% 미만만 학습시킨다 (LORA와 동일, 랭크(rank)값에 비례)"}),"\n",(0,r.jsx)(e.li,{children:"추가 모델 저장 공간: 매우 작다(LORA 부분만 추가 저장, 베이스는 공유)"}),"\n",(0,r.jsx)(e.li,{children:"메모리 요구사항: 매우 작다(4비트 양자화 모델 + LORA 모듈)"}),"\n",(0,r.jsx)(e.li,{children:"추론 속도 영향: 거의 없다(양자화된 모델 속도에 좌우, 행렬 연산 병합 시 동일)"}),"\n",(0,r.jsxs)(e.li,{children:["장점\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"자원 사용을 극소화한 다(대형 모델도 단일 GPU로 파인튜닝 가능)."}),"\n",(0,r.jsx)(e.li,{children:"성능 손실이 거의 없다."}),"\n",(0,r.jsx)(e.li,{children:"LORA 장점을 모두 포 함한다."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["단점\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"양자화 지원 라이브러 리가 필요하다."}),"\n",(0,r.jsx)(e.li,{children:"4비트 연산으로 구현 복잡도가 증가한다."}),"\n",(0,r.jsx)(e.li,{children:"일부 정밀도가 저하되 어 성능의 차이가 날 수 있다."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.h3,{id:"데이터셋-참고",children:[(0,r.jsx)(e.a,{className:"header-anchor","aria-hidden":"true",href:"#데이터셋-참고",children:"#"}),"데이터셋 참고"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://commoncrawl.org/",rel:"noopener noreferrer",target:"_blank",children:"https://commoncrawl.org/"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://www.microsoft.com/en-us/research/project/microsoft-research-open-data/",rel:"noopener noreferrer",target:"_blank",children:"https://www.microsoft.com/en-us/research/project/microsoft-research-open-data/"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://www.kaggle.com/datasets",rel:"noopener noreferrer",target:"_blank",children:"https://www.kaggle.com/datasets"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://huggingface.co/datasets",rel:"noopener noreferrer",target:"_blank",children:"https://huggingface.co/datasets"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://data.go.kr",rel:"noopener noreferrer",target:"_blank",children:"https://data.go.kr"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://aihub.or.kr",rel:"noopener noreferrer",target:"_blank",children:"https://aihub.or.kr"})}),"\n"]})]})}function h(){let n=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:e}={...(0,l.a)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(s,{...n})}):s(n)}h.__RSPRESS_PAGE_META={},h.__RSPRESS_PAGE_META["artificialIntelligence%2F60-FineTuning.md"]={toc:[{id:"소개",text:"소개",depth:3},{id:"방법",text:"방법",depth:3},{id:"장점",text:"장점",depth:3},{id:"단점",text:"단점",depth:3},{id:"튜닝",text:"튜닝",depth:3},{id:"데이터셋-거버넌스-구축",text:"데이터셋 거버넌스 구축",depth:3},{id:"데이터-증강-craft-방법론",text:"데이터 증강 CRAFT 방법론",depth:3},{id:"기타-용어",text:"기타 용어",depth:3},{id:"풀파인튜닝-vs-lora-vs-qlora",text:"풀파인튜닝 vs LoRA vs QLoRA",depth:3},{id:"데이터셋-참고",text:"데이터셋 참고",depth:3}],title:"Fine-tuning 微调",headingTitle:"Fine-tuning 微调",frontmatter:{}}}}]);